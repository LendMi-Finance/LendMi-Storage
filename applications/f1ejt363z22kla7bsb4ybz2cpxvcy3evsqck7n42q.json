{
  "Version": "1.3",
  "ID": "f1ejt363z22kla7bsb4ybz2cpxvcy3evsqck7n42q",
  "Issue Number": "46",
  "Client": {
    "Name": "Thomas Coleman",
    "Region": "United States",
    "Industry": "Life Science / Healthcare",
    "Website": "https://registry.opendata.aws/nrel-pds-porotomo/；https://github.com/openEDI/documentation/blob/main/PoroTomo/PoroTomo.md",
    "Social Media": "https://github.com/openEDI/documentation/blob/main/PoroTomo/PoroTomo.md",
    "Social Media Type": "Slack",
    "Role": "Data Preparer"
  },
  "Project": {
    "Brief history of your project and organization": "The data were collected during March 2016 at the PoroTomo Natural Laboratory in Brady's Hot Springs, Nevada.\n\nSilixa’s iDAS (TM) was used for DAS data acquisition with 1.021 m channel spacing and a guage length of 10 m. Data in this archive are in .sgy and .h5 files with raw units (radians of optical phase change per time sample) (Miller, et al.).\n\nHorizontal DAS (DASH) data collection began 3/8/2016, paused, and then started again on 3/11/2016 and ended 3/26/2016 using zigzag trenched fiber optic cabels. Vertical DAS (DASV) data collection began 3/17/2016 and ended 3/28/2016 using a fiber optic cable through the first 363 m of a vertical well.\n\nThe resampled DASH data are Matlab files with data for the surface DAS (DASH) array deployed at the PoroTomo natural laboratory in March 2016. Each file contains 30 seconds worth of data for 8721 channels. These files have been resampled in time from the original data and have a sample rate of 100 samples/second.\n\nThe nodal seismometer data consists of continuous and windowed (to vibroseis sweep) SAC files. Nodal data collection began between 3/6/2016 and 3/11/2016 depending on the station, and ended between 3/26/2016 and 3/28/2016 also depending on the station. Station names, locations, start times, stop times, and orientations can be found in the nodal seismometer metadata linked below.",
    "Is this project associated with other projects/ecosystem stakeholders?": "No",
    "Describe the data being stored onto Filecoin": "The data were collected during March 2016 at the PoroTomo Natural Laboratory in Brady's Hot Springs, Nevada.\n\nSilixa’s iDAS (TM) was used for DAS data acquisition with 1.021 m channel spacing and a guage length of 10 m. Data in this archive are in .sgy and .h5 files with raw units (radians of optical phase change per time sample) (Miller, et al.).\n\nHorizontal DAS (DASH) data collection began 3/8/2016, paused, and then started again on 3/11/2016 and ended 3/26/2016 using zigzag trenched fiber optic cabels. Vertical DAS (DASV) data collection began 3/17/2016 and ended 3/28/2016 using a fiber optic cable through the first 363 m of a vertical well.\n\nThe resampled DASH data are Matlab files with data for the surface DAS (DASH) array deployed at the PoroTomo natural laboratory in March 2016. Each file contains 30 seconds worth of data for 8721 channels. These files have been resampled in time from the original data and have a sample rate of 100 samples/second.\n\nThe nodal seismometer data consists of continuous and windowed (to vibroseis sweep) SAC files. Nodal data collection began between 3/6/2016 and 3/11/2016 depending on the station, and ended between 3/26/2016 and 3/28/2016 also depending on the station. Station names, locations, start times, stop times, and orientations can be found in the nodal seismometer metadata linked below.",
    "Where was the data currently stored in this dataset sourced from": "AWS Cloud",
    "How do you plan to prepare the dataset": "Use the AWS s3 command line tool to download the original data, record all file information in the database, and create a tar file based on the file size. The size of the tar file is controlled between 16-32G. If a single file is larger than 32G, the split tool will be used to split it. The size of the file after splitting is within 32G. The number of file splits will be recorded and named with a suffix like part_N. When creating the tar file, the data packaging rules will be recorded in the database for index generation. The CID corresponding to the packaged sector can be found based on the index.\n",
    "Please share a sample of the data (a link to a file, an image, a table, etc., are good ways to do this.)": "Total: 172.2 TiB\n\ns3://nrel-pds-porotomo/Nodal/nodal_metadata：1.3-15.5 MB\ns3://nrel-pds-porotomo/Nodal/nodal_sac：45-173 MB\n\ns3://nrel-pds-porotomo/DAS/SEG-Y/DASH:\n\nsize: ~1-2 GB each\nshape: 8721 traces x 30000 samples/trace\ns3://nrel-pds-porotomo/DAS/SEG-Y/DASH/Resampled:\n\nformat: MATLAB files created through resampling of SEG-Y files\nsize: ~0.19 MB\nshape of 'data' object: 30000 npts x 8721 nch\ns3://nrel-pds-porotomo/DAS/SEG-Y/DASV:\n\nsize: ~0.01-0.02 GB each\nshape: 384 traces x 30000 samples/trace\n\nMore comprehensive information can be found here:\nhttps://data.openei.org/s3_viewer?bucket=nrel-pds-porotomo&prefix=DAS%2FH5%2FDASH_NV-test-site-explosion_standardized%2F\n\n",
    "Confirm that this is a public dataset that can be retrieved by anyone on the network (i.e., no specific permissions or access rights are required to view the data)": "[x] I confirm",
    "What is the expected retrieval frequency for this data": "Yearly",
    "For how long do you plan to keep this dataset stored on Filecoin": "1.5 to 2 years",
    "In which geographies do you plan on making storage deals": "Greater China, Asia other than Greater China, Africa, Europe",
    "How will you be distributing your data to storage providers": "HTTP or FTP server, Cloud storage (i.e. S3)",
    "Please list the provider IDs and location of the storage providers you will be working with. Note that it is a requirement to list a minimum of 5 unique provider IDs, and that your client address will be verified against this list in the future": "f02869125 France\nf02916974 US\nf02952530 Thailand\nf03233356 South Korea\nf02874347 US\nf03233304 United States\nf02924003 United States\nf02893152 Vietnam\nf02866013 Russia\nf03601451   HongKong",
    "Can you confirm that you will follow the Fil+ guideline (Data owner should engage at least 4 SPs and no single SP ID should receive >30% of a client's allocated DataCap)": "Yes"
  },
  "Datacap": {
    "Type": "ldn-v3",
    "Data Type": "Slingshot",
    "Total Requested Amount": "2PiB",
    "Single Size Dataset": "200TiB",
    "Replicas": 10,
    "Weekly Allocation": "2PiB"
  },
  "Lifecycle": {
    "State": "Granted",
    "Validated At": "2025-06-16 02:21:04.558783711 UTC",
    "Validated By": "Rongze92",
    "Active": true,
    "Updated At": "2025-06-16 02:21:04.558779701 UTC",
    "Active Request ID": "152c0718-fd3a-432f-95ad-8f9ccd5b1511",
    "On Chain Address": "f1ejt363z22kla7bsb4ybz2cpxvcy3evsqck7n42q",
    "Multisig Address": "false",
    "edited": true
  },
  "Allocation Requests": [
    {
      "ID": "7d90a7b0-31ec-4a98-a5a3-aaf609d2a1f6",
      "Request Type": "First",
      "Created At": "2025-04-28 08:08:15.001494648 UTC",
      "Updated At": "2025-04-28 08:08:15.001495955 UTC",
      "Active": false,
      "Allocation Amount": "109951162777600 B",
      "Signers": [
        {
          "Github Username": "Rongze92",
          "Signing Address": "f12mckci3omexgzoeosjvstcfxfe4vqw7owdia3da",
          "Created At": "2025-04-28 08:10:01.597000000 UTC",
          "Message CID": "bafy2bzacedfiixdxtl744dfleouua5agij77mz5dl3h2wsz33sx7hutbtawew"
        }
      ]
    },
    {
      "ID": "4b7a94e4-1cdd-48ce-93a5-8a351108da19",
      "Request Type": "Refill",
      "Created At": "2025-04-30 06:41:51.970813720 UTC",
      "Updated At": "2025-04-30 06:41:51.970814317 UTC",
      "Active": false,
      "Allocation Amount": "281474976710656B",
      "Signers": [
        {
          "Github Username": "Rongze92",
          "Signing Address": "f12mckci3omexgzoeosjvstcfxfe4vqw7owdia3da",
          "Created At": "2025-04-30 06:43:30.540000000 UTC",
          "Message CID": "bafy2bzacectnjthxuvzxqsks7gqdb5qtg3rq7hc3kcjpbcefneutianvrduxy"
        }
      ]
    },
    {
      "ID": "2b39a0aa-1039-4c34-80b2-f871e03d592c",
      "Request Type": "Refill",
      "Created At": "2025-06-06 06:56:19.468931689 UTC",
      "Updated At": "2025-06-06 06:56:19.468932369 UTC",
      "Active": false,
      "Allocation Amount": "562949953421312B",
      "Signers": [
        {
          "Github Username": "Rongze92",
          "Signing Address": "f12mckci3omexgzoeosjvstcfxfe4vqw7owdia3da",
          "Created At": "2025-06-06 06:58:10.832000000 UTC",
          "Message CID": "bafy2bzacebdjmxd3kt6p3a4rqghznsg2dqmig5quwme423v3gp2fmr63xbgv2"
        }
      ]
    },
    {
      "ID": "152c0718-fd3a-432f-95ad-8f9ccd5b1511",
      "Request Type": "Refill",
      "Created At": "2025-06-16 02:18:13.228661375 UTC",
      "Updated At": "2025-06-16 02:18:13.228662338 UTC",
      "Active": false,
      "Allocation Amount": "1125899906842624B",
      "Signers": [
        {
          "Github Username": "Rongze92",
          "Signing Address": "f12mckci3omexgzoeosjvstcfxfe4vqw7owdia3da",
          "Created At": "2025-06-16 02:21:02.225000000 UTC",
          "Message CID": "bafy2bzaced3ua6yw6try5uhnao3uo7e5kww2gpffxogxd4xfxmw5bfyrbgeci"
        }
      ]
    }
  ]
}